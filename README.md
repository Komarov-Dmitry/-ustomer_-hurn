# Проверочный проект: Модели машинного обучения с учителем — Методы на основе деревьев

## Описание проекта

Этот проект посвящён созданию и анализу моделей машинного обучения для предсказания оттока (churn) клиентов. Мы исследуем различия моделей на основе деревьев, таких как Decision Tree, Random Forest, AdaBoost, и Gradient Boosting, и анализируем данные для подогрева гипотез и улучшения моделей.

## Цель проекта

Цель проекта — разработать и применить модели на основе деревьев для предсказания вероятности того, что клиент уйдёт в отток. Также мы изучаем влияние различных признаков на данное событие.

## Содержание
## Часть 1: Анализ данных

На первом этапе происходит проверка типов данных и наличия отсутствующих значений с использованием метода .info(). Это помогает нам оценить состояние исходного набора данных и подготовить его для дальнейшего анализа.

## Часть 2: Исследование и сегментация данных

Здесь проводится исследование признаков, включая анализ различных характеристик абонентов, которые могут помочь в моделировании оттока.

## Часть 3: Анализ оттока

### Создание когорт

Мы создаём когорты на основе времени (tenure), которое клиент провёл с компанией, и вычисляем процент оттока для каждой когорты. Это помогает идентифицировать, как длительность пребывания клиента влияет на вероятность его оттока.

### Более крупные когорты

На основе tenure мы создаём более крупные категории для более детализированного анализа:
- '0-12 месяцев'
- '12-24 месяцев'
- '24-48 месяцев'
- 'Более 48 месяцев'

## Часть 4: Моделирование

### Одно дерево решений (Decision Tree)

Создаём и оцениваем модель Decision Tree, включая:
- Обучение и кросс-валидацию.
- Оценку метрик (classification report и confusion matrix).
- Важность признаков.
- Визуализацию дерева решений.

### Случайный лес (Random Forest)

Построение модели случайного леса и составление отчётов на основе предсказаний на тестовом наборе данных.

### Расширяемые деревья (Boosted Trees)

Использование моделей AdaBoost и Gradient Boosting с анализом качества предсказаний через отчёты и матрицы путаницы.

## Заключение

В рамках проекта были получены лучшие результаты с моделью AdaBoostClassifier, несмотря на отсутствие глубокой оптимизации гиперпараметров. Большая часть моделей показывала схожие результаты при текущей настройке данных.
